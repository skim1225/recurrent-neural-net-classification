{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23kMXKm_A7KC"
      },
      "outputs": [],
      "source": [
        "# 7.1 - Implement a Recurrent Neural Network (RNN) using Pytorch\n",
        "\n",
        "# Define RNN model\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes, rnn_type='RNN'):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        if rnn_type == 'RNN':\n",
        "          self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True) # (a) Build a one-layer RNN...\n",
        "        elif rnn_type == 'LSTM':\n",
        "          self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)  # (b) Build a linear classifier...\n",
        "        self.rnn_type = rnn_type  # Store the RNN type\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)  # Initialize cell state for LSTM\n",
        "            out, _ = self.rnn(x, (h0, c0)) # LSTM returns (out, (hn, cn))\n",
        "        else:\n",
        "            out, _ = self.rnn(x, h0) # RNN returns (out, hn)\n",
        "        logit = self.fc(out[:, -1, :])\n",
        "        prob = nn.functional.softmax(logit, dim=1)\n",
        "        return prob, logit\n",
        "\n",
        "# fix seed\n",
        "SEED = 1\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# load data\n",
        "\n",
        "data_dir = 'human+activity+recognition+using+smartphones/UCI HAR Dataset'\n",
        "train_dataset = UCIHARDataset(subset='train', data_dir=data_dir)\n",
        "test_dataset = UCIHARDataset(subset='test', data_dir=data_dir)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# hyperparams\n",
        "input_size = 9\n",
        "hidden_size = 16\n",
        "num_layers = 1\n",
        "num_classes = 6\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 16\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# helper func\n",
        "def train_and_evaluate_rnn(model, train_loader, test_loader, num_epochs, optimizer, criterion):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            _, activity_logit = model(inputs)\n",
        "            loss = criterion(activity_logit, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs, _ = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    test_acc = correct / total\n",
        "    return test_acc\n",
        "\n",
        "# 7.1.a - Build a one-layer RNN that read the inputs (input dimension=9) and produce hidden  features (use feature dimension=16).\n",
        "# 7.1.b - Build a linear classifier that classifies the activity labels (number of activity=6) from hidden features.\n",
        "# 7.1.c Train the model using Cross Entropy Loss and Adam optimizer.\n",
        "# 7.1.d Train for 10 epochs with batch size=16, learning rate=0.001. Report test accuracy.\n",
        "model_1_layer = RNNClassifier(input_size, hidden_size, num_layers, num_classes, rnn_type='RNN')\n",
        "optimizer_1_layer = optim.Adam(model_1_layer.parameters(), lr=learning_rate)\n",
        "test_acc_1_layer = train_and_evaluate_rnn(model_1_layer, train_loader, test_loader, num_epochs, optimizer_1_layer, criterion)\n",
        "print(\"7.1.d Test Accuracy (10 epochs, 16 batch size, lr 0.0011 layer RNN, hidden_size=16):\", test_acc_1_layer)\n",
        "\n",
        "# 7.2 - Train and evaluate the model with different architectures and report test accuracy for each model:\n",
        "\n",
        "# 7.2.a - Change feature dimension to 64\n",
        "hidden_size_a = 64\n",
        "model_a = RNNClassifier(input_size, hidden_size_a, num_layers, num_classes, rnn_type='RNN')\n",
        "optimizer_a = optim.Adam(model_a.parameters(), lr=learning_rate)\n",
        "test_acc_a = train_and_evaluate_rnn(model_a, train_loader, test_loader, num_epochs, optimizer_a, criterion)\n",
        "print(\"7.2.a Test Accuracy (feature dimension=64:\", test_acc_a)\n",
        "\n",
        "# 7.2.b - Change the number of RNN layers to 2,3,4 (keep feature dimension=16)\n",
        "for num_layers_b in [2, 3, 4]:\n",
        "    model_b = RNNClassifier(input_size, hidden_size, num_layers_b, num_classes, rnn_type='RNN')\n",
        "    optimizer_b = optim.Adam(model_b.parameters(), lr=learning_rate)\n",
        "    test_acc_b = train_and_evaluate_rnn(model_b, train_loader, test_loader, num_epochs, optimizer_b, criterion)\n",
        "    print(\"7.2.b Test Accuracy (\", num_layers_b, \"layer RNN, hidden_size=16):\", test_acc_b)\n",
        "\n",
        "# 7.2.c - Change RNN to LSTM (keep feature dimension=16 and number of layers=1)\n",
        "model_c = RNNClassifier(input_size, hidden_size, 1, num_classes, rnn_type='LSTM')\n",
        "optimizer_c = optim.Adam(model_c.parameters(), lr=learning_rate)\n",
        "test_acc_c = train_and_evaluate_rnn(model_c, train_loader, test_loader, num_epochs, optimizer_c, criterion)\n",
        "print(\"7.2.c Test Accuracy (1 layer LSTM, hidden_size=16):\", test_acc_c)"
      ]
    }
  ]
}